{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import operator\n",
    "import re,string\n",
    "from patsy import dmatrices\n",
    "%pylab inline\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import random\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('google1.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date Written</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Current/Former</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Recommendation?</th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Main Text</th>\n",
       "      <th>Pros</th>\n",
       "      <th>Cons</th>\n",
       "      <th>Advice to management</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Operations manager\"</td>\n",
       "      <td>Oct 5, 2018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Current Employee</td>\n",
       "      <td>Operations Manager</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Recommends</td>\n",
       "      <td>Positive Outlook</td>\n",
       "      <td>I have been working at Google full-time (More ...</td>\n",
       "      <td>Perks, food, spaces, culture, health care and ...</td>\n",
       "      <td>Flat org, hard to grow</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Moving at the speed of light, burn out is ine...</td>\n",
       "      <td>Jun 21, 2013</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>Doesn't Recommend</td>\n",
       "      <td>Negative Outlook</td>\n",
       "      <td>Show More</td>\n",
       "      <td>1) Food, food, food. 15+ cafes on main campus ...</td>\n",
       "      <td>1) Work/life balance. What balance? All those ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Great balance between big-company security an...</td>\n",
       "      <td>May 10, 2014</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Current Employee</td>\n",
       "      <td>Software Engineer III</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Recommends</td>\n",
       "      <td>Positive Outlook</td>\n",
       "      <td>Show More</td>\n",
       "      <td>* If you're a software engineer, you're among ...</td>\n",
       "      <td>* It *is* becoming larger, and with it comes g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"The best place I've worked and also the most ...</td>\n",
       "      <td>Feb 8, 2015</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Current Employee</td>\n",
       "      <td>Anonymous Employee</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>Recommends</td>\n",
       "      <td>Positive Outlook</td>\n",
       "      <td>Show More</td>\n",
       "      <td>You can't find a more well-regarded company th...</td>\n",
       "      <td>I live in SF so the commute can take between 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Unique, one of a kind dream job\"</td>\n",
       "      <td>Jul 19, 2018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Former Employee</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Recommends</td>\n",
       "      <td>Neutral Outlook</td>\n",
       "      <td>Roll back the trend towards becoming a regular...</td>\n",
       "      <td>Google is a world of its own. At every other c...</td>\n",
       "      <td>If you don't work in MTV (HQ), you will be giv...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Date Written  Rating  \\\n",
       "0                               \"Operations manager\"   Oct 5, 2018     5.0   \n",
       "1  \"Moving at the speed of light, burn out is ine...  Jun 21, 2013     4.0   \n",
       "2  \"Great balance between big-company security an...  May 10, 2014     5.0   \n",
       "3  \"The best place I've worked and also the most ...   Feb 8, 2015     5.0   \n",
       "4                  \"Unique, one of a kind dream job\"  Jul 19, 2018     5.0   \n",
       "\n",
       "     Current/Former              Job Title           Location  \\\n",
       "0  Current Employee     Operations Manager       New York, NY   \n",
       "1   Former Employee        Program Manager  Mountain View, CA   \n",
       "2  Current Employee  Software Engineer III       New York, NY   \n",
       "3  Current Employee     Anonymous Employee  Mountain View, CA   \n",
       "4   Former Employee      Software Engineer    Los Angeles, CA   \n",
       "\n",
       "     Recommendation?           Outlook  \\\n",
       "0         Recommends  Positive Outlook   \n",
       "1  Doesn't Recommend  Negative Outlook   \n",
       "2         Recommends  Positive Outlook   \n",
       "3         Recommends  Positive Outlook   \n",
       "4         Recommends   Neutral Outlook   \n",
       "\n",
       "                                           Main Text  \\\n",
       "0  I have been working at Google full-time (More ...   \n",
       "1                                          Show More   \n",
       "2                                          Show More   \n",
       "3                                          Show More   \n",
       "4  Roll back the trend towards becoming a regular...   \n",
       "\n",
       "                                                Pros  \\\n",
       "0  Perks, food, spaces, culture, health care and ...   \n",
       "1  1) Food, food, food. 15+ cafes on main campus ...   \n",
       "2  * If you're a software engineer, you're among ...   \n",
       "3  You can't find a more well-regarded company th...   \n",
       "4  Google is a world of its own. At every other c...   \n",
       "\n",
       "                                                Cons  Advice to management  \n",
       "0                             Flat org, hard to grow                   NaN  \n",
       "1  1) Work/life balance. What balance? All those ...                   NaN  \n",
       "2  * It *is* becoming larger, and with it comes g...                   NaN  \n",
       "3  I live in SF so the commute can take between 1...                   NaN  \n",
       "4  If you don't work in MTV (HQ), you will be giv...                   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7632, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Pros and Cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pros = df['Pros']\n",
    "cons = df['Cons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean punctuation and white spaces\n",
    "pros_clean = pros.apply(lambda x:re.sub(r'[^\\w\\s]', ' ', x.lower()))\n",
    "pros_clean = pros_clean.apply(lambda x:re.sub(r'(\\\\n+)', ' ', x))\n",
    "pros_clean = pros_clean.apply(lambda x:re.sub(r'^b[\\'\\\"\\'\"\\\"''\\s]', '', x.lower()))\n",
    "pros_clean = pros_clean.apply(lambda x:re.sub(r'\\s+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing and removing stop words\n",
    "stop = set(stopwords.words('english'))\n",
    "punc = string.punctuation\n",
    "pros_clean = pros_clean.apply(lambda x: [word for word in word_tokenize(x) if word not in stop])\n",
    "pros_clean = pros_clean.apply(lambda x: [word for word in x if word not in punc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting frequency distribution\n",
    "all_pros = pros_clean.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pros_dist = nltk.FreqDist(all_pros)\n",
    "pros_dict = pd.DataFrame.from_dict(pros_dist,orient='index').reset_index()\n",
    "pros_dict.columns = ['word','frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perks</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spaces</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>culture</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>health</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  frequency\n",
       "0    perks       1206\n",
       "1     food       1075\n",
       "2   spaces         12\n",
       "3  culture        885\n",
       "4   health         55"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pros_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pros_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>great</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>work</td>\n",
       "      <td>2899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>people</td>\n",
       "      <td>2185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>good</td>\n",
       "      <td>1817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>benefits</td>\n",
       "      <td>1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perks</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>company</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>google</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>smart</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>environment</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>culture</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>free</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>working</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>place</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>amazing</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>best</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>lots</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>really</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>life</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  frequency\n",
       "74         great       2998\n",
       "6           work       2899\n",
       "49        people       2185\n",
       "107         good       1817\n",
       "92      benefits       1219\n",
       "0          perks       1206\n",
       "33       company       1132\n",
       "1           food       1075\n",
       "31        google       1030\n",
       "81         smart        909\n",
       "78   environment        898\n",
       "3        culture        885\n",
       "20          free        736\n",
       "201      working        621\n",
       "69         place        607\n",
       "122      amazing        600\n",
       "79          best        575\n",
       "48          lots        446\n",
       "67        really        427\n",
       "7           life        417"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pros_dict.sort_values(by='frequency', ascending=0)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('smart', 'people'), 475), (('free', 'food'), 461), (('place', 'work'), 340), (('work', 'life'), 332), (('life', 'balance'), 316), (('great', 'benefits'), 301), (('great', 'people'), 291), (('work', 'environment'), 276), (('people', 'great'), 261), (('great', 'perks'), 248), (('people', 'work'), 194), (('great', 'company'), 186), (('great', 'place'), 185), (('great', 'work'), 180), (('work', 'great'), 175), (('co', 'workers'), 163), (('great', 'culture'), 155), (('good', 'work'), 150), (('company', 'work'), 143), (('perks', 'great'), 127)]\n"
     ]
    }
   ],
   "source": [
    "pro_bigrams = ngrams(all_pros, 2)\n",
    "print(Counter(pro_bigrams).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('work', 'life', 'balance'), 309), (('great', 'place', 'work'), 125), (('smart', 'people', 'great'), 85), (('great', 'people', 'great'), 63), (('good', 'work', 'life'), 62), (('great', 'work', 'environment'), 58), (('great', 'company', 'work'), 50), (('great', 'people', 'work'), 47), (('great', 'work', 'life'), 46), (('great', 'perks', 'great'), 46), (('best', 'place', 'work'), 43), (('free', 'food', 'great'), 41), (('good', 'place', 'work'), 41), (('life', 'balance', 'great'), 39), (('people', 'great', 'benefits'), 37), (('work', 'smart', 'people'), 35), (('smart', 'co', 'workers'), 35), (('work', 'environment', 'great'), 34), (('free', 'food', 'free'), 34), (('place', 'work', 'great'), 33)]\n"
     ]
    }
   ],
   "source": [
    "pro_trigrams = ngrams(all_pros, 3)\n",
    "print(Counter(pro_trigrams).most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look at cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_clean = cons.apply(lambda x:re.sub(r'[^\\w\\s]', ' ', x.lower()))\n",
    "cons_clean = cons_clean.apply(lambda x:re.sub(r'(\\\\n+)', ' ', x))\n",
    "cons_clean = cons_clean.apply(lambda x:re.sub(r'^b[\\'\\\"\\'\"\\\"''\\s]', '', x.lower()))\n",
    "cons_clean = cons_clean.apply(lambda x:re.sub(r'\\s+', ' ', x))\n",
    "\n",
    "#tokenizing and removing stop words\n",
    "stop = set(stopwords.words('english'))\n",
    "punc = string.punctuation\n",
    "cons_clean = cons_clean.apply(lambda x: [word for word in word_tokenize(x) if word not in stop])\n",
    "cons_clean = cons_clean.apply(lambda x: [word for word in x if word not in punc])\n",
    "\n",
    "#getting frequency distribution\n",
    "all_cons = cons_clean.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_dist = nltk.FreqDist(all_cons)\n",
    "cons_dict = pd.DataFrame.from_dict(cons_dist,orient='index').reset_index()\n",
    "cons_dict.columns = ['word','frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>work</td>\n",
       "      <td>1583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>company</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>google</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>people</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>get</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>big</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>management</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>many</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>much</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>time</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>like</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>sometimes</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>cons</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>working</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>really</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>long</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>lot</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>good</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>life</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  frequency\n",
       "5          work       1583\n",
       "157     company       1366\n",
       "17       google        991\n",
       "173      people        820\n",
       "93          get        746\n",
       "195         big        689\n",
       "2          hard        633\n",
       "24   management        558\n",
       "171        many        543\n",
       "174        much        512\n",
       "19         time        512\n",
       "407        like        453\n",
       "63    sometimes        449\n",
       "140        cons        445\n",
       "238     working        400\n",
       "184      really        386\n",
       "118        long        382\n",
       "101         lot        377\n",
       "305        good        375\n",
       "6          life        370"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_dict.sort_values(by='frequency', ascending=0)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('work', 'life'), 274), (('life', 'balance'), 263), (('big', 'company'), 260), (('long', 'hours'), 139), (('large', 'company'), 134), (('hard', 'get'), 94), (('middle', 'management'), 93), (('mountain', 'view'), 85), (('feel', 'like'), 81), (('get', 'promoted'), 74), (('many', 'people'), 72), (('smart', 'people'), 68), (('working', 'google'), 64), (('difficult', 'get'), 56), (('hard', 'work'), 55), (('things', 'done'), 54), (('work', 'hard'), 53), (('get', 'things'), 49), (('red', 'tape'), 48), (('full', 'time'), 46)]\n"
     ]
    }
   ],
   "source": [
    "con_bigrams = ngrams(all_cons, 2)\n",
    "print(Counter(con_bigrams).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('work', 'life', 'balance'), 261), (('get', 'things', 'done'), 46), (('google', 'big', 'company'), 25), (('many', 'smart', 'people'), 20), (('great', 'place', 'work'), 19), (('cons', 'working', 'google'), 19), (('nothing', 'nothing', 'nothing'), 17), (('like', 'big', 'company'), 17), (('hard', 'get', 'promoted'), 16), (('hard', 'get', 'things'), 16), (('work', 'long', 'hours'), 15), (('big', 'company', 'hard'), 13), (('easy', 'get', 'lost'), 13), (('long', 'work', 'hours'), 13), (('feel', 'like', 'small'), 12), (('good', 'work', 'life'), 12), (('slow', 'decision', 'making'), 11), (('get', 'anything', 'done'), 11), (('life', 'balance', 'difficult'), 11), (('big', 'company', 'problems'), 11)]\n"
     ]
    }
   ],
   "source": [
    "con_trigrams = ngrams(all_cons, 3)\n",
    "print(Counter(con_trigrams).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement not upgraded as not directly required: smart-open>=1.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement not upgraded as not directly required: numpy>=1.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.14.3)\n",
      "Requirement not upgraded as not directly required: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.1.0)\n",
      "Requirement not upgraded as not directly required: six>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.11.0)\n",
      "Requirement not upgraded as not directly required: boto>=2.32 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim) (2.48.0)\n",
      "Requirement not upgraded as not directly required: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim) (1.9.21)\n",
      "Requirement not upgraded as not directly required: bz2file in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
      "Requirement not upgraded as not directly required: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
      "Requirement not upgraded as not directly required: s3transfer<0.2.0,>=0.1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
      "Requirement not upgraded as not directly required: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
      "Requirement not upgraded as not directly required: botocore<1.13.0,>=1.12.21 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.21)\n",
      "Requirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement not upgraded as not directly required: idna<2.7,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
      "Requirement not upgraded as not directly required: urllib3<1.23,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
      "Requirement not upgraded as not directly required: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
      "Requirement not upgraded as not directly required: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.21->boto3->smart-open>=1.2.1->gensim) (2.7.3)\n",
      "Requirement not upgraded as not directly required: docutils>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.21->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's combine both pros and cons into a column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pros_Cons'] = df['Pros'] + df['Cons']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df = 5).fit(df['Pros_Cons']) ## Using our custom Tokenizer function using Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2744"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Total number of unique vocab after removing not-so-useful-words\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectorized = vect.transform(df['Pros_Cons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _cs_matrix.toarray of <7632x2744 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 176470 stored elements in Compressed Sparse Row format>>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectorized.toarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7632, 2744)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc =0\n",
    "feature_index = X_vectorized[doc,:].nonzero()[1]\n",
    "feature_names = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2698, 2467, 2249, 1793, 1698, 1404, 1114, 1099, 1072,  961,  564,\n",
       "        340,  129])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_scores = zip(feature_index, [X_vectorized[doc, x] for x in feature_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {}\n",
    "for w, s in [(feature_names[i],s) for (i, s) in tfidf_scores]:\n",
    "    di[w] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#di = sorted(di, lambda x )\n",
    "sorted_by_value = sorted(di.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'work': 0.1232610070805007,\n",
       " 'to': 0.10518537008554617,\n",
       " 'spaces': 0.4839252883931002,\n",
       " 'perks': 0.1923677026601747,\n",
       " 'org': 0.3874682226001394,\n",
       " 'life': 0.22158148300243125,\n",
       " 'health': 0.3842343894640443,\n",
       " 'hard': 0.23140797505806665,\n",
       " 'grow': 0.33036879104158556,\n",
       " 'food': 0.19871400478340195,\n",
       " 'culture': 0.20369984560500268,\n",
       " 'care': 0.31689873548618547,\n",
       " 'and': 0.10765138519794966}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>TFIDF Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spaces</td>\n",
       "      <td>0.483925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>org</td>\n",
       "      <td>0.387468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>health</td>\n",
       "      <td>0.384234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grow</td>\n",
       "      <td>0.330369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>care</td>\n",
       "      <td>0.316899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hard</td>\n",
       "      <td>0.231408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>life</td>\n",
       "      <td>0.221581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>culture</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>food</td>\n",
       "      <td>0.198714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perks</td>\n",
       "      <td>0.192368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>work</td>\n",
       "      <td>0.123261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>and</td>\n",
       "      <td>0.107651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>0.105185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  TFIDF Score\n",
       "2    spaces     0.483925\n",
       "4       org     0.387468\n",
       "6    health     0.384234\n",
       "8      grow     0.330369\n",
       "11     care     0.316899\n",
       "7      hard     0.231408\n",
       "5      life     0.221581\n",
       "10  culture     0.203700\n",
       "9      food     0.198714\n",
       "3     perks     0.192368\n",
       "0      work     0.123261\n",
       "12      and     0.107651\n",
       "1        to     0.105185"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(di.items()), columns=['Word', 'TFIDF Score']).sort_values(by='TFIDF Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnc = df['Pros_Cons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_values = 'Focus on the user and all else will follow. It’s best to do one thing really, really well. Fast is better than slow. Democracy on the web works. You don’t need to be at your desk to need an answer. You can make money without doing evil. There’s always more information out there. The need for information crosses all borders. You can be serious without a suit. Great just isn’t good enough.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "'''remove punctuation, lowercase, stem'''\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-e88dd113d6aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcosine_sim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpros_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcore_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-90ac927e9eac>\u001b[0m in \u001b[0;36mcosine_sim\u001b[1;34m(text1, text2)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m         \"\"\"\n\u001b[1;32m-> 1381\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 266\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "cosine_sim(pros_clean.sum(), core_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim('a little bird', 'a little bird')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
